{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q transformers datasets accelerate scikit-learn wandb"
      ],
      "metadata": {
        "id": "GpJXIEI9HlVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "-XuEmHztHlSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"syedkhalid076/Sentiment-Analysis\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "2XjmEeEPHlPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0])\n",
        "print(dataset[\"train\"][1])\n",
        "print(dataset[\"train\"][2])"
      ],
      "metadata": {
        "id": "FIbjVjEZHlM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "num_labels = 3  # negative, neutral, positive\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "\n",
        "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id"
      ],
      "metadata": {
        "id": "X3jemQYKHlJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "tokenized_dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "rSVctidJHlHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset_size = 40000\n",
        "val_subset_size = 8000\n",
        "\n",
        "small_train = tokenized_dataset[\"train\"].select(range(train_subset_size))\n",
        "small_val = tokenized_dataset[\"validation\"].select(range(val_subset_size))\n",
        "\n",
        "len(small_train), len(small_val)"
      ],
      "metadata": {
        "id": "uD8Vrdh9HlER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
      ],
      "metadata": {
        "id": "c0sg-KBgHlBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "logging_dir = \"./logs\"\n",
        "output_dir = \"./bert_sentiment_output\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=logging_dir,\n",
        "    logging_steps=50,\n",
        "    report_to=[\"wandb\"],\n",
        ")"
      ],
      "metadata": {
        "id": "fzwwe0i2Hk-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_val,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "y0K7fhjmHk7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "train_result\n",
        "\n",
        "trainer.save_model(\"./best_bert_sentiment\")\n",
        "tokenizer.save_pretrained(\"./best_bert_sentiment\")"
      ],
      "metadata": {
        "id": "t3w5PnL3Hk5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
        "print(\"Validation metrics:\", val_metrics)\n",
        "\n",
        "test_metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
        "print(\"Test metrics:\", test_metrics)"
      ],
      "metadata": {
        "id": "gAFQeZpKHk1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "label_names = [\"negative\", \"neutral\", \"positive\"]\n",
        "cm_df = pd.DataFrame(cm, index=label_names, columns=label_names)\n",
        "cm_df"
      ],
      "metadata": {
        "id": "BtTFqnkPHkzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(\"cuda\")\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
        "    pred_id = int(np.argmax(probs))\n",
        "    return label_names[pred_id], probs\n",
        "\n",
        "print(predict_sentiment(\"This movie was absolutely amazing!\"))\n",
        "print(predict_sentiment(\"It was okay, nothing special.\"))\n",
        "print(predict_sentiment(\"Terrible experience, I hated it.\"))"
      ],
      "metadata": {
        "id": "xhBuQd6YIC3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"best_bert_sentiment\", \"zip\", \"best_bert_sentiment\")"
      ],
      "metadata": {
        "id": "3QXGEX-UW-PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_bert_sentiment.zip\")"
      ],
      "metadata": {
        "id": "JuuKVWrxXCF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}